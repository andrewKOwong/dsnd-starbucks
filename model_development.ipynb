{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bc7ff5e-ab37-4906-a102-6cd1dd929525",
   "metadata": {},
   "source": [
    "Let's do some model development."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e54311-4e01-491e-a907-6441115cc715",
   "metadata": {},
   "source": [
    "We're trying to prod people to spend money. Assuming no long term effects like: retention rates, customer annoyance, long term habit building, customer satisfaction. So we're trying to prod them to spend money over the short term.\n",
    "\n",
    "Business scenarios:\n",
    "\n",
    "- Assuming no transaction history built into model.\n",
    "    - New customer, no demo info, what to offer them.\n",
    "        - Basically no info at all. Offer aggregate best, or in model solely with customer length.\n",
    "    - New customer, demo info, what to offer them.\n",
    "        - Use model based on age, gender, income, possibly in model with customer length.\n",
    "    - Existing customer, no demo info, what to offer them.\n",
    "        - Use model based on customer length. Possibly by year as bin.\n",
    "    - Existing customer, demo info, what to offer them.\n",
    "        - Use model based on age, gender, income, customer length.\n",
    "        \n",
    "So we're looking for a way to pick out which offer to give a customer.\n",
    "\n",
    "In our data, customers are only exposed to a maximum of 6 offers, with a median of 4 unique offers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326821c3-1f65-4f46-86c1-4e87ee0e6e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import normalize, StandardScaler\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Sometimes use display instead of print\n",
    "from IPython.display import display\n",
    "\n",
    "# debugging\n",
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1feeb91b-091c-4148-982f-54046fa9fea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the cleaned data\n",
    "portfolio = pd.read_csv('./data/portfolio_clean.csv')\n",
    "profile = pd.read_csv('./data/profile_clean.csv')\n",
    "transcript = pd.read_csv('./data/transcript_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff153a6-ab58-4327-bcc1-2aca8de4e693",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(portfolio.head())\n",
    "display(profile.head())\n",
    "display(transcript.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8287bc9-ed31-4398-abcd-69fd46bf350f",
   "metadata": {},
   "source": [
    "How to define success?\n",
    "\n",
    "Base line behaviour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c10e708-337d-4449-8424-ed95d0c13346",
   "metadata": {},
   "source": [
    "Split by customers? yes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8524c9bc-72e5-453e-9e4a-c9d8dea1db7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge everything first.\n",
    "# df = transcript.merge(profile, how='left', on='customer_id').merge(portfolio, how='left', on='offer_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcc8dae-fc9a-406e-933c-8ee50d519c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.rename(columns={'reward_x':'reward_transaction', 'reward_y':'offer_reward'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b70f26-0f56-4b93-b8a3-994729e7a9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15405565-d197-4425-8eff-87ba79a9da29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of individual df's from grouping by customer id.\n",
    "# train_customers, test_customers = train_test_split([e[1] for e in df.groupby('customer_id')], test_size=0.3, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8d4bc1-7a94-48d4-a2a0-81d3b891dd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(len(train_customers))\n",
    "# display(len(test_customers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bef19fd-e1d7-4ed5-9bfd-d564074d5777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def split_transactions_and_offers(customer_list_of_df, transaction_key='transaction'):\n",
    "#     \"\"\"\n",
    "#     Filters a agglomerated dataframe into transactions and offers.\n",
    "    \n",
    "#     Input:\n",
    "#     customers_list_of_df - individual customer dfs in a list\n",
    "#     transaction_key      - str for transaction events\n",
    "    \n",
    "#     Returns:\n",
    "#         List of tuples of transaction and offer event dfs by customer id.\n",
    "#     \"\"\"\n",
    "#     output = []\n",
    "#     # Iterate through the list and split\n",
    "#     for customer in customer_list_of_df:\n",
    "#         # Mask to get transactions\n",
    "#         select = customer.event == transaction_key\n",
    "#         # Filter for transactions and \n",
    "#         output.append((customer[select], customer[~select]))\n",
    "    \n",
    "#     return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cb91d8-2570-4afa-8746-aa79c121bab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_event_split = split_transactions_and_offers(train_customers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2f5790-82de-47b2-b0fd-e66ba636f96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(train_event_split[1][0])\n",
    "# print('\\n'*4)\n",
    "# display(train_event_split[1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65e78e0-83fe-4301-883c-c2d57984be50",
   "metadata": {},
   "source": [
    "# Simple KNN or something for only one type of offer? e.g. offer completion.\n",
    "\n",
    "If I had to get a very simple classifier working to:\n",
    "- predict whether off number 1, a bogo offer, was completed or not.\n",
    "- predict based on demographic data.\n",
    "    \n",
    "To do that I would need to classify whether someone:\n",
    "- got offer 1\n",
    "- completed offer 1 within the specified duration\n",
    "\n",
    "I'll split customers into training and validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1597d067-046c-4e98-94ed-6ebbec60b9cd",
   "metadata": {},
   "source": [
    "To figure out if customers completed an offer or not, I'll need to:\n",
    "- filter the transcript for 'offer_received' events for offer 1\n",
    "- for each 'offer_received' event:\n",
    "    - filter the transcript for 'offer_completed' events with time >= time of the received event and time <= t + duration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c09739-9ec2-469e-94a1-9040e7209e66",
   "metadata": {},
   "source": [
    "It's like\n",
    "\n",
    "1) Grab the data by offer\n",
    "2) Prep the data\n",
    "3) Do the modelling and report results.\n",
    "    - KNN pipeline\n",
    "    - other model pipeline\n",
    "4) Overall function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e233b69-66de-48f0-a924-2faa1a56757a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_offer_with_demo_action_models(transcript_df, profile_df, random_state=7):\n",
    "    \"\"\"\n",
    "    \n",
    "    Input:\n",
    "    \n",
    "    \n",
    "    Returns:\n",
    "    A dict containing keys for the offer id and values that are dicts with:\n",
    "        model   - GridSearchCV model for the offer.\n",
    "        X_train - Training data features.\n",
    "        X_test  - Test data features.\n",
    "        y_train - Training data targets.\n",
    "        y_test  - Test data targets.\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4ab6034-c7a1-411b-8728-b48416c28b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_offer_action_data(transcript_df, profile_df, offer_id, action_type, contain_demo=True):\n",
    "    \"\"\"\n",
    "    For a given offer id, generates a df combining customer profiles with \n",
    "    whether they viewed/completed the offer (if they received the offer) over\n",
    "    the course of the experiment.\n",
    "    \n",
    "    Also dummies gender data and converts \"became_member_on\" to \n",
    "    durations of how long a customer has been a customer.\n",
    "    \n",
    "    Input:\n",
    "    transcript_df - Transaction/event transcript dataframe.\n",
    "    profile_df    - Customer profiles.\n",
    "    offer_id      - Offer id to process.\n",
    "    action_type   - 'offer_completed' or 'offer_viewed'.\n",
    "    contain_demo  - If True, returns only customers having age/gender/income demographic data.\n",
    "                    If False, returns only customers without demographic data.\n",
    "    \n",
    "    Returns:\n",
    "    offer_profile - Dataframe containing customer profiles and \n",
    "    \"\"\"\n",
    "    tr = transcript_df\n",
    "    pro = profile_df\n",
    "    \n",
    "    # Get set of offering completing and non-completing customer ids\n",
    "    offer_customers = set(tr[(tr.offer_id == offer_id) & (tr.event == 'offer_received')].customer_id)\n",
    "    offer_completed = set(tr[(tr.offer_id == offer_id) & (tr.event == action_type)].customer_id)\n",
    "    offer_incomplete = offer_customers - offer_completed\n",
    "    \n",
    "    # Appending 0/1 for incomplete/complete to customer profile data\n",
    "    profile_complete = pro[pro.customer_id.isin(offer_completed)].assign(offer_complete = 1)\n",
    "    profile_incomplete = pro[pro.customer_id.isin(offer_incomplete)].assign(offer_complete = 0)\n",
    "    \n",
    "    offer_profile = pd.concat([profile_complete, profile_incomplete]).sort_values('customer_id')\n",
    "    \n",
    "    # Customers w/ demographic data\n",
    "    if contain_demo == True:\n",
    "        offer_profile = offer_profile.dropna()\n",
    "    # Customers missing demographic data\n",
    "    else:\n",
    "        offer_profile = offer_profile[offer_profile.isna().any(axis=1)]\n",
    "        \n",
    "    # Clean the data\n",
    "    ## Get dummies for gender\n",
    "    offer_profile = pd.concat([offer_profile,\n",
    "                               pd.get_dummies(offer_profile.gender, prefix=\"gender\")],\n",
    "                              axis=1)\n",
    "    # Change membership date to duration in years of how long customer\n",
    "    # has been a customer.\n",
    "    customer_duration = pd.to_datetime(offer_profile.became_member_on)\n",
    "    customer_duration = (customer_duration.max() - customer_duration).dt.days/365\n",
    "    offer_profile['customer_duration'] = customer_duration\n",
    "    \n",
    "    # Drop unnecessary columns\n",
    "    offer_profile = offer_profile.drop(columns=['gender', 'became_member_on', 'customer_id'])\n",
    "    \n",
    "    return offer_profile\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e920e1-91d9-432c-93e5-470bb6bee189",
   "metadata": {},
   "outputs": [],
   "source": [
    "offer1_profile_demo_info = get_offer_completion_data(transcript, profile, offer_id=1, contain_demo=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5184ac3a-350a-467e-9e9d-92b8b5eaa621",
   "metadata": {},
   "outputs": [],
   "source": [
    "offer1_profile_demo_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde35ac4-e15a-46eb-89fa-2c4718ac8739",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_x_y(df, y_key='offer_complete'):\n",
    "    \"\"\"\n",
    "    Takes a df and separates it into X and y by y_key.\n",
    "    \n",
    "    Input:\n",
    "    df     - A dataframe.\n",
    "    y_key  - str of the y target column.\n",
    "    \n",
    "    Returns:\n",
    "    X      - Dataframe without y_key column.\n",
    "    y      - Series from y_key column.\n",
    "    \"\"\"\n",
    "    # Get X and standardize it.\n",
    "    # i.e. mean = 0, unit variance\n",
    "    X = df.drop(columns=y_key)    \n",
    "    y = df[y_key]\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980769bb-b9a8-4d88-a804-459b8beb9e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = separate_x_y(offer1_profile_demo_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c6b1f5-e379-4264-abd6-8d42bb03f662",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1e0a2e-1451-4245-903d-852bef116fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_KNN_pipeline_and_fit_CV(X_train, y_train, verbosity=3, n_neighbors_grid=[1,5,10,20,40,80,160,320,640,1000]):\n",
    "    \"\"\"\n",
    "    Builds a KNN model and fits on training data with cross validation.\n",
    "    \n",
    "    Standardizes X data first before feeding into a KNN model.\n",
    "    \n",
    "    Input:\n",
    "    X_train          - Training data features.\n",
    "    y_train          - Training data targets.\n",
    "    verbosity        - 0, 1, 2, or 3 to control GridSearchCV output.\n",
    "    n_neighbors_grid - Search grid for the number of neighbors for the KNN model.\n",
    "    \n",
    "    Returns:\n",
    "    model            - a GridSearchCV model.\n",
    "    \n",
    "    \"\"\"\n",
    "    pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                         ('knn', KNeighborsClassifier())])\n",
    "    \n",
    "    param_grid = [{'knn__n_neighbors': n_neighbors_grid}]\n",
    "    model = GridSearchCV(pipe, scoring='f1', param_grid=param_grid, cv=5, refit=True, verbose=verbosity, return_train_score=True)\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"Best params: {model.best_params_}.\")\n",
    "    print(f\"Best score: {round(model.best_score_, 5)}.\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3868e254-4a5f-485a-ac22-57062a6de1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_CV_model_scores(model):\n",
    "    \"\"\"\n",
    "    Gets training and cross validation scores form a model.\n",
    "    \n",
    "    Input:\n",
    "    model - an sklearn GridSearchCV model.\n",
    "    \n",
    "    Returns:\n",
    "    mean_train_score - GridSearchCV model mean training scores.\n",
    "    mean_test_scores - GridSearchCV model mean cross validation scores.\n",
    "    \"\"\"\n",
    "    return model.cv_results_['mean_train_score'], model.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc7c7a0-f417-414c-98d6-6150b97a45a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = build_KNN_pipeline_and_fit_CV(X_train, y_train, verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2afbfe-fdab-4e24-a5a9-f93e1e89779a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score, validation_score = get_CV_model_scores(knn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e170164-6d27-4c98-b9dc-74e0bc291ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = [e['knn__n_neighbors'] for e in model.cv_results_['params']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed7b2c0-4e17-4b87-9820-886e7fc5cbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,20))\n",
    "param = 'knn__n_neighbors'\n",
    "sns.lineplot(ax=ax, x=n_neighbors, y=train_score, label='train')\n",
    "sns.lineplot(ax=ax, x=n_neighbors, y=validation_score, label='validation')\n",
    "ax.axvline(model.best_params_[param])\n",
    "ax.set_xlabel(param)\n",
    "ax.set_ylabel('f1 score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e675719-43be-491f-b266-437a9c4826f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_RFC_pipeline_and_fit_CV(X_train,\n",
    "                                  y_train,\n",
    "                                  verbosity=3,\n",
    "                                  param_grid=[{'rfc__n_estimators': [10, 100],\n",
    "                                               'rfc__max_depth': [100, None],\n",
    "                                               'rfc__min_samples_split': [2, 5, 10, 20],\n",
    "                                               'rfc__min_samples_leaf': [1, 2, 4, 8]\n",
    "                                             }],\n",
    "                                  random_state=7):\n",
    "    \"\"\"\n",
    "    Builds a random forest classifier and fits on training data with cross validation.\n",
    "    \n",
    "    Standardizes X data first before feeding into a RF model.\n",
    "    \n",
    "    See https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
    "    for hyperparameter tuning example.\n",
    "    \n",
    "    Input:\n",
    "    X_train          - Training data features.\n",
    "    y_train          - Training data targets.\n",
    "    verbosity        - 0, 1, 2, or 3 to control GridSearchCV output.\n",
    "    param_grid       - Search grid for the RF model. Prefix params with 'rfc__'.\n",
    "    random_state     - random int for the RF model.\n",
    "    \n",
    "    Returns:\n",
    "    model            - a GridSearchCV model.\n",
    "    \"\"\"\n",
    "    pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                         ('rfc', RandomForestClassifier())])\n",
    "    \n",
    " \n",
    "    \n",
    "    model = GridSearchCV(pipe, scoring='f1', param_grid=param_grid, cv=5, refit=True, verbose=verbosity, return_train_score=True)\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"Best params: {model.best_params_}.\")\n",
    "    print(f\"Best score: {round(model.best_score_, 5)}.\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1cc314-5a27-491c-b6f2-cf77a2dc103b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_model = build_RFC_pipeline_and_fit_CV(X_train, y_train, verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd1885e-8a19-4052-9f1f-a52fb9753636",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score, validation_score = get_CV_model_scores(rfc_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ba104a-ccbb-4ed3-94c2-3880c66b9857",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = [e['knn__n_neighbors'] for e in model.cv_results_['params']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965da450-17ec-4370-9cab-b143b23d10a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,20))\n",
    "param = 'knn__n_neighbors'\n",
    "sns.lineplot(ax=ax, x=n_neighbors, y=train_score, label='train')\n",
    "sns.lineplot(ax=ax, x=n_neighbors, y=validation_score, label='validation')\n",
    "ax.axvline(model.best_params_[param])\n",
    "ax.set_xlabel(param)\n",
    "ax.set_ylabel('f1 score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd4f34e-6f86-44e4-aba6-a869539548f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83984a3d-916c-4ae1-9935-b83932c388ea",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit ('dsci': conda)",
   "language": "python",
   "name": "python394jvsc74a57bd0f0cece84d5b7094323c4cd37c9c6a7c87a529d4917679faac7fe812b406a8aca"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
