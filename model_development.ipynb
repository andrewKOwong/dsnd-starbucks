{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bc7ff5e-ab37-4906-a102-6cd1dd929525",
   "metadata": {},
   "source": [
    "Let's do some model development."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e54311-4e01-491e-a907-6441115cc715",
   "metadata": {},
   "source": [
    "We're trying to prod people to spend money. Assuming no long term effects like: retention rates, customer annoyance, long term habit building, customer satisfaction. So we're trying to prod them to spend money over the short term.\n",
    "\n",
    "Business scenarios:\n",
    "\n",
    "- Assuming no transaction history built into model.\n",
    "    - New customer, no demo info, what to offer them.\n",
    "        - Basically no info at all. Offer aggregate best, or in model solely with customer length.\n",
    "    - New customer, demo info, what to offer them.\n",
    "        - Use model based on age, gender, income, possibly in model with customer length.\n",
    "    - Existing customer, no demo info, what to offer them.\n",
    "        - Use model based on customer length. Possibly by year as bin.\n",
    "    - Existing customer, demo info, what to offer them.\n",
    "        - Use model based on age, gender, income, customer length.\n",
    "        \n",
    "So we're looking for a way to pick out which offer to give a customer.\n",
    "\n",
    "In our data, customers are only exposed to a maximum of 6 offers, with a median of 4 unique offers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "326821c3-1f65-4f46-86c1-4e87ee0e6e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import normalize, StandardScaler\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Sometimes use display instead of print\n",
    "from IPython.display import display\n",
    "\n",
    "# debugging\n",
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1feeb91b-091c-4148-982f-54046fa9fea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the cleaned data\n",
    "portfolio = pd.read_csv('./data/portfolio_clean.csv')\n",
    "profile = pd.read_csv('./data/profile_clean.csv')\n",
    "transcript = pd.read_csv('./data/transcript_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ff153a6-ab58-4327-bcc1-2aca8de4e693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offer_id</th>\n",
       "      <th>web</th>\n",
       "      <th>email</th>\n",
       "      <th>mobile</th>\n",
       "      <th>social</th>\n",
       "      <th>offer_type</th>\n",
       "      <th>duration</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>reward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>bogo</td>\n",
       "      <td>168</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>bogo</td>\n",
       "      <td>120</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>informational</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>bogo</td>\n",
       "      <td>168</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>discount</td>\n",
       "      <td>240</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   offer_id  web  email  mobile  social     offer_type  duration  difficulty  \\\n",
       "0         1    0      1       1       1           bogo       168          10   \n",
       "1         2    1      1       1       1           bogo       120          10   \n",
       "2         3    1      1       1       0  informational        96           0   \n",
       "3         4    1      1       1       0           bogo       168           5   \n",
       "4         5    1      1       0       0       discount       240          20   \n",
       "\n",
       "   reward  \n",
       "0      10  \n",
       "1      10  \n",
       "2       0  \n",
       "3       5  \n",
       "4       5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>became_member_on</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-02-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>55.0</td>\n",
       "      <td>112000.0</td>\n",
       "      <td>2017-07-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-07-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>F</td>\n",
       "      <td>75.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>2017-05-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-08-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id gender   age    income became_member_on\n",
       "0            1    NaN   NaN       NaN       2017-02-12\n",
       "1            2      F  55.0  112000.0       2017-07-15\n",
       "2            3    NaN   NaN       NaN       2018-07-12\n",
       "3            4      F  75.0  100000.0       2017-05-09\n",
       "4            5    NaN   NaN       NaN       2017-08-04"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>time</th>\n",
       "      <th>event</th>\n",
       "      <th>amount</th>\n",
       "      <th>reward</th>\n",
       "      <th>offer_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>offer_received</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>offer_received</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>offer_received</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>offer_received</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>offer_received</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  time           event  amount  reward  offer_id\n",
       "0            4     0  offer_received     NaN     NaN       4.0\n",
       "1            5     0  offer_received     NaN     NaN       5.0\n",
       "2            6     0  offer_received     NaN     NaN      10.0\n",
       "3            7     0  offer_received     NaN     NaN       7.0\n",
       "4            8     0  offer_received     NaN     NaN       2.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(portfolio.head())\n",
    "display(profile.head())\n",
    "display(transcript.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8287bc9-ed31-4398-abcd-69fd46bf350f",
   "metadata": {},
   "source": [
    "How to define success?\n",
    "\n",
    "Base line behaviour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c10e708-337d-4449-8424-ed95d0c13346",
   "metadata": {},
   "source": [
    "Split by customers? yes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8524c9bc-72e5-453e-9e4a-c9d8dea1db7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge everything first.\n",
    "# df = transcript.merge(profile, how='left', on='customer_id').merge(portfolio, how='left', on='offer_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcc8dae-fc9a-406e-933c-8ee50d519c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.rename(columns={'reward_x':'reward_transaction', 'reward_y':'offer_reward'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b70f26-0f56-4b93-b8a3-994729e7a9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15405565-d197-4425-8eff-87ba79a9da29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of individual df's from grouping by customer id.\n",
    "# train_customers, test_customers = train_test_split([e[1] for e in df.groupby('customer_id')], test_size=0.3, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8d4bc1-7a94-48d4-a2a0-81d3b891dd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(len(train_customers))\n",
    "# display(len(test_customers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bef19fd-e1d7-4ed5-9bfd-d564074d5777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def split_transactions_and_offers(customer_list_of_df, transaction_key='transaction'):\n",
    "#     \"\"\"\n",
    "#     Filters a agglomerated dataframe into transactions and offers.\n",
    "    \n",
    "#     Input:\n",
    "#     customers_list_of_df - individual customer dfs in a list\n",
    "#     transaction_key      - str for transaction events\n",
    "    \n",
    "#     Returns:\n",
    "#         List of tuples of transaction and offer event dfs by customer id.\n",
    "#     \"\"\"\n",
    "#     output = []\n",
    "#     # Iterate through the list and split\n",
    "#     for customer in customer_list_of_df:\n",
    "#         # Mask to get transactions\n",
    "#         select = customer.event == transaction_key\n",
    "#         # Filter for transactions and \n",
    "#         output.append((customer[select], customer[~select]))\n",
    "    \n",
    "#     return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cb91d8-2570-4afa-8746-aa79c121bab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_event_split = split_transactions_and_offers(train_customers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2f5790-82de-47b2-b0fd-e66ba636f96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(train_event_split[1][0])\n",
    "# print('\\n'*4)\n",
    "# display(train_event_split[1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65e78e0-83fe-4301-883c-c2d57984be50",
   "metadata": {},
   "source": [
    "# Simple KNN or something for only one type of offer? e.g. offer completion.\n",
    "\n",
    "If I had to get a very simple classifier working to:\n",
    "- predict whether off number 1, a bogo offer, was completed or not.\n",
    "- predict based on demographic data.\n",
    "    \n",
    "To do that I would need to classify whether someone:\n",
    "- got offer 1\n",
    "- completed offer 1 within the specified duration\n",
    "\n",
    "I'll split customers into training and validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1597d067-046c-4e98-94ed-6ebbec60b9cd",
   "metadata": {},
   "source": [
    "To figure out if customers completed an offer or not, I'll need to:\n",
    "- filter the transcript for 'offer_received' events for offer 1\n",
    "- for each 'offer_received' event:\n",
    "    - filter the transcript for 'offer_completed' events with time >= time of the received event and time <= t + duration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c09739-9ec2-469e-94a1-9040e7209e66",
   "metadata": {},
   "source": [
    "It's like\n",
    "\n",
    "1) Grab the data by offer\n",
    "2) Prep the data\n",
    "3) Do the modelling and report results.\n",
    "    - KNN pipeline\n",
    "    - other model pipeline\n",
    "4) Overall function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e233b69-66de-48f0-a924-2faa1a56757a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_offer_with_demo_action_models(transcript_df,\n",
    "                                        profile_df,\n",
    "                                        portfolio_df,\n",
    "                                        action_dict={'bogo': 'offer_completed',\n",
    "                                                     'discount': 'offer_completed',\n",
    "                                                     'informational': 'offer_viewed'},\n",
    "                                        model_type='knn',\n",
    "                                        test_size=0.3,\n",
    "                                        verbosity=3,\n",
    "                                        random_state=7):\n",
    "    \"\"\"\n",
    "    Get models for offer viewing/completion.\n",
    "    \n",
    "    Input:\n",
    "    transcript_df - Transaction/event transcript dataframe.\n",
    "    profile_df    - Customer profiles.\n",
    "    portfolio_df  - Offer portfolio.\n",
    "    action_dict   - The action should the model predict for per offer.\n",
    "    model_type    - Classifier to use. One of 'knn' (k nearest neighbours)\n",
    "                    or 'rfc' (random forest classifier).\n",
    "    test_size     - Split size for training/test sets.\n",
    "    verbosity     - GridSearchCV verbosity level.\n",
    "    random_state  - random_state to pass down to model building etc.\n",
    "                  \n",
    "    \n",
    "    Returns:\n",
    "    A dict containing keys for the offer id and values that are dicts with:\n",
    "        model   - GridSearchCV model for the offer.\n",
    "        X_train - Training data features.\n",
    "        X_test  - Test data features.\n",
    "        y_train - Training data targets.\n",
    "        y_test  - Test data targets.\n",
    "    \"\"\"\n",
    "    output={}\n",
    "    \n",
    "    # Get offer ids and offer types,\n",
    "    # then generate action type for based on offer type\n",
    "    # (e.g. informational offers can only be viewed, not completed).\n",
    "    offer_ids, offer_types = portfolio_df['offer_id'], portfolio_df['offer_type']\n",
    "    offer_actions = [action_dict[offer_type] for offer_type in offer_types]\n",
    "    \n",
    "    for offer_id, action in zip(offer_ids, offer_actions):\n",
    "        # Get combined customer profile + action completion df\n",
    "        offer_profile = get_offer_action_data(transcript_df, profile_df, offer_id, action, contain_demo=True)\n",
    "        # Get X and y \n",
    "        X, y = separate_x_y(offer_profile)\n",
    "        # Split training and test\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=test_size,\n",
    "                                                    random_state=random_state)\n",
    "        # Switch to build and cross validate a model.\n",
    "        if model_type == 'knn':\n",
    "            model = build_KNN_pipeline_and_fit_CV(X_train, y_train, verbosity=verbosity)\n",
    "        elif model_type == 'rfc':\n",
    "            model = build_RFC_pipeline_and_fit_CV(X_train, y_train, verbosity=verbosity)\n",
    "        else:\n",
    "            raise ValueError(f\"Model of type {model_type} not implemented.\")\n",
    "        \n",
    "        # A output dict is generated for each offer id.\n",
    "        output[offer_id] = {'model': model, \n",
    "                              'X_train': X_train,\n",
    "                              'X_test': X_test,\n",
    "                              'y_train': y_train,\n",
    "                              'y_test': y_test\n",
    "                             }\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4ab6034-c7a1-411b-8728-b48416c28b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_offer_action_data(transcript_df, profile_df, offer_id, action_type, contain_demo=True):\n",
    "    \"\"\"\n",
    "    For a given offer id, generates a df combining customer profiles with \n",
    "    whether they viewed/completed the offer (if they received the offer) over\n",
    "    the course of the experiment.\n",
    "    \n",
    "    Also dummies gender data and converts \"became_member_on\" to \n",
    "    durations of how long a customer has been a customer.\n",
    "    \n",
    "    Input:\n",
    "    transcript_df - Transaction/event transcript dataframe.\n",
    "    profile_df    - Customer profiles.\n",
    "    offer_id      - Offer id to process.\n",
    "    action_type   - 'offer_completed' or 'offer_viewed'.\n",
    "    contain_demo  - If True, returns only customers having age/gender/income demographic data.\n",
    "                    If False, returns only customers without demographic data.\n",
    "    \n",
    "    Returns:\n",
    "    offer_profile - Dataframe containing customer profiles and offer view/completion status.\n",
    "    \"\"\"\n",
    "    tr = transcript_df\n",
    "    pro = profile_df\n",
    "    \n",
    "    # Get set of offering completing and non-completing customer ids\n",
    "    offer_customers = set(tr[(tr.offer_id == offer_id) & (tr.event == 'offer_received')].customer_id)\n",
    "    offer_completed = set(tr[(tr.offer_id == offer_id) & (tr.event == action_type)].customer_id)\n",
    "    offer_incomplete = offer_customers - offer_completed\n",
    "    \n",
    "    # Appending 0/1 for incomplete/complete to customer profile data\n",
    "    profile_complete = pro[pro.customer_id.isin(offer_completed)].assign(offer_complete = 1)\n",
    "    profile_incomplete = pro[pro.customer_id.isin(offer_incomplete)].assign(offer_complete = 0)\n",
    "    \n",
    "    offer_profile = pd.concat([profile_complete, profile_incomplete]).sort_values('customer_id')\n",
    "    \n",
    "    # Customers w/ demographic data\n",
    "    if contain_demo == True:\n",
    "        offer_profile = offer_profile.dropna()\n",
    "    # Customers missing demographic data\n",
    "    else:\n",
    "        offer_profile = offer_profile[offer_profile.isna().any(axis=1)]\n",
    "        \n",
    "    # Clean the data\n",
    "    ## Get dummies for gender\n",
    "    offer_profile = pd.concat([offer_profile,\n",
    "                               pd.get_dummies(offer_profile.gender, prefix=\"gender\")],\n",
    "                              axis=1)\n",
    "    # Change membership date to duration in years of how long customer\n",
    "    # has been a customer.\n",
    "    customer_duration = pd.to_datetime(offer_profile.became_member_on)\n",
    "    customer_duration = (customer_duration.max() - customer_duration).dt.days/365\n",
    "    offer_profile['customer_duration'] = customer_duration\n",
    "    \n",
    "    # Drop unnecessary columns\n",
    "    offer_profile = offer_profile.drop(columns=['gender', 'became_member_on', 'customer_id'])\n",
    "    \n",
    "    return offer_profile\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fde35ac4-e15a-46eb-89fa-2c4718ac8739",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_x_y(df, y_key='offer_complete'):\n",
    "    \"\"\"\n",
    "    Takes a df and separates it into X and y by y_key.\n",
    "    \n",
    "    Input:\n",
    "    df     - A dataframe.\n",
    "    y_key  - str of the y target column.\n",
    "    \n",
    "    Returns:\n",
    "    X      - Dataframe without y_key column.\n",
    "    y      - Series from y_key column.\n",
    "    \"\"\"\n",
    "    # Get X and standardize it.\n",
    "    # i.e. mean = 0, unit variance\n",
    "    X = df.drop(columns=y_key)    \n",
    "    y = df[y_key]\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb1e0a2e-1451-4245-903d-852bef116fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_KNN_pipeline_and_fit_CV(X_train, y_train, verbosity=3, n_neighbors_grid=[1,5,10,20,40,80,160,320,640,1000]):\n",
    "    \"\"\"\n",
    "    Builds a KNN model and fits on training data with cross validation.\n",
    "    \n",
    "    Standardizes X data first before feeding into a KNN model.\n",
    "    \n",
    "    Input:\n",
    "    X_train          - Training data features.\n",
    "    y_train          - Training data targets.\n",
    "    verbosity        - 0, 1, 2, or 3 to control GridSearchCV output.\n",
    "    n_neighbors_grid - Search grid for the number of neighbors for the KNN model.\n",
    "    \n",
    "    Returns:\n",
    "    model            - a GridSearchCV model.\n",
    "    \n",
    "    \"\"\"\n",
    "    pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                         ('knn', KNeighborsClassifier())])\n",
    "    \n",
    "    param_grid = [{'knn__n_neighbors': n_neighbors_grid}]\n",
    "    model = GridSearchCV(pipe, scoring='f1', param_grid=param_grid, cv=5, refit=True, verbose=verbosity, return_train_score=True)\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"Best params: {model.best_params_}.\")\n",
    "    print(f\"Best score: {round(model.best_score_, 5)}.\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9302dbfc-85f5-4239-b628-c4c5b7d20114",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_RFC_pipeline_and_fit_CV(X_train,\n",
    "                                  y_train,\n",
    "                                  verbosity=3,\n",
    "                                  param_grid=[{'rfc__n_estimators': [10, 100],\n",
    "                                               'rfc__max_depth': [100, None],\n",
    "                                               'rfc__min_samples_split': [2, 5, 10, 20],\n",
    "                                               'rfc__min_samples_leaf': [1, 2, 4, 8]\n",
    "                                             }],\n",
    "                                  random_state=7):\n",
    "    \"\"\"\n",
    "    Builds a random forest classifier and fits on training data with cross validation.\n",
    "    \n",
    "    Standardizes X data first before feeding into a RF model.\n",
    "    \n",
    "    See https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
    "    for hyperparameter tuning example.\n",
    "    \n",
    "    Input:\n",
    "    X_train          - Training data features.\n",
    "    y_train          - Training data targets.\n",
    "    verbosity        - 0, 1, 2, or 3 to control GridSearchCV output.\n",
    "    param_grid       - Search grid for the RF model. Prefix params with 'rfc__'.\n",
    "    random_state     - random int for the RF model.\n",
    "    \n",
    "    Returns:\n",
    "    model            - a GridSearchCV model.\n",
    "    \"\"\"\n",
    "    pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                         ('rfc', RandomForestClassifier())])\n",
    "    \n",
    " \n",
    "    \n",
    "    model = GridSearchCV(pipe, scoring='f1', param_grid=param_grid, cv=5, refit=True, verbose=verbosity, return_train_score=True)\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"Best params: {model.best_params_}.\")\n",
    "    print(f\"Best score: {round(model.best_score_, 5)}.\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3868e254-4a5f-485a-ac22-57062a6de1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_CV_model_scores(model):\n",
    "    \"\"\"\n",
    "    Gets training and cross validation scores form a model.\n",
    "    \n",
    "    Input:\n",
    "    model - an sklearn GridSearchCV model.\n",
    "    \n",
    "    Returns:\n",
    "    mean_train_score - GridSearchCV model mean training scores.\n",
    "    mean_test_scores - GridSearchCV model mean cross validation scores.\n",
    "    \"\"\"\n",
    "    return model.cv_results_['mean_train_score'], model.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03ee2804-17dc-408a-a50e-45c064d4b2a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Best params: {'knn__n_neighbors': 160}.\n",
      "Best score: 0.75268.\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Best params: {'knn__n_neighbors': 160}.\n",
      "Best score: 0.71826.\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Best params: {'knn__n_neighbors': 160}.\n",
      "Best score: 0.70603.\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Best params: {'knn__n_neighbors': 1000}.\n",
      "Best score: 0.7945.\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Best params: {'knn__n_neighbors': 320}.\n",
      "Best score: 0.7185.\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Best params: {'knn__n_neighbors': 320}.\n",
      "Best score: 0.86337.\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Best params: {'knn__n_neighbors': 320}.\n",
      "Best score: 0.87384.\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Best params: {'knn__n_neighbors': 20}.\n",
      "Best score: 0.94924.\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Best params: {'knn__n_neighbors': 640}.\n",
      "Best score: 0.78888.\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Best params: {'knn__n_neighbors': 320}.\n",
      "Best score: 0.77563.\n"
     ]
    }
   ],
   "source": [
    "knn_models = build_offer_with_demo_action_models(transcript, profile, portfolio, model_type='knn', verbosity=1, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "85f5201f-72ed-4730-8279-bc573b2ecef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
      "Best params: {'rfc__max_depth': None, 'rfc__min_samples_leaf': 8, 'rfc__min_samples_split': 20, 'rfc__n_estimators': 10}.\n",
      "Best score: 0.75759.\n",
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
      "Best params: {'rfc__max_depth': 100, 'rfc__min_samples_leaf': 8, 'rfc__min_samples_split': 5, 'rfc__n_estimators': 100}.\n",
      "Best score: 0.72039.\n",
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
      "Best params: {'rfc__max_depth': 100, 'rfc__min_samples_leaf': 8, 'rfc__min_samples_split': 20, 'rfc__n_estimators': 10}.\n",
      "Best score: 0.68864.\n",
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
      "Best params: {'rfc__max_depth': None, 'rfc__min_samples_leaf': 8, 'rfc__min_samples_split': 10, 'rfc__n_estimators': 100}.\n",
      "Best score: 0.79049.\n",
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
      "Best params: {'rfc__max_depth': 100, 'rfc__min_samples_leaf': 8, 'rfc__min_samples_split': 20, 'rfc__n_estimators': 100}.\n",
      "Best score: 0.72899.\n",
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
      "Best params: {'rfc__max_depth': None, 'rfc__min_samples_leaf': 8, 'rfc__min_samples_split': 10, 'rfc__n_estimators': 100}.\n",
      "Best score: 0.86143.\n",
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
      "Best params: {'rfc__max_depth': 100, 'rfc__min_samples_leaf': 8, 'rfc__min_samples_split': 20, 'rfc__n_estimators': 100}.\n",
      "Best score: 0.87123.\n",
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
      "Best params: {'rfc__max_depth': 100, 'rfc__min_samples_leaf': 1, 'rfc__min_samples_split': 20, 'rfc__n_estimators': 100}.\n",
      "Best score: 0.94962.\n",
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
      "Best params: {'rfc__max_depth': 100, 'rfc__min_samples_leaf': 8, 'rfc__min_samples_split': 10, 'rfc__n_estimators': 100}.\n",
      "Best score: 0.77337.\n",
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
      "Best params: {'rfc__max_depth': 100, 'rfc__min_samples_leaf': 8, 'rfc__min_samples_split': 20, 'rfc__n_estimators': 10}.\n",
      "Best score: 0.77229.\n"
     ]
    }
   ],
   "source": [
    "rfc_models = build_offer_with_demo_action_models(transcript, profile, portfolio, model_type='rfc', verbosity=1, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e170164-6d27-4c98-b9dc-74e0bc291ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = [e['knn__n_neighbors'] for e in model.cv_results_['params']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed7b2c0-4e17-4b87-9820-886e7fc5cbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,20))\n",
    "param = 'knn__n_neighbors'\n",
    "sns.lineplot(ax=ax, x=n_neighbors, y=train_score, label='train')\n",
    "sns.lineplot(ax=ax, x=n_neighbors, y=validation_score, label='validation')\n",
    "ax.axvline(model.best_params_[param])\n",
    "ax.set_xlabel(param)\n",
    "ax.set_ylabel('f1 score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965da450-17ec-4370-9cab-b143b23d10a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,20))\n",
    "param = 'knn__n_neighbors'\n",
    "sns.lineplot(ax=ax, x=n_neighbors, y=train_score, label='train')\n",
    "sns.lineplot(ax=ax, x=n_neighbors, y=validation_score, label='validation')\n",
    "ax.axvline(model.best_params_[param])\n",
    "ax.set_xlabel(param)\n",
    "ax.set_ylabel('f1 score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd4f34e-6f86-44e4-aba6-a869539548f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83984a3d-916c-4ae1-9935-b83932c388ea",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit ('dsci': conda)",
   "language": "python",
   "name": "python394jvsc74a57bd0f0cece84d5b7094323c4cd37c9c6a7c87a529d4917679faac7fe812b406a8aca"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
